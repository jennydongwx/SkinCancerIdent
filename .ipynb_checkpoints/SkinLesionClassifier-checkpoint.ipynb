{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pytorch\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import models,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_df = pd.read_csv('data/HAM10000_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the 7 types of skin lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nv       6705\n",
       "mel      1113\n",
       "bkl      1099\n",
       "bcc       514\n",
       "akiec     327\n",
       "vasc      142\n",
       "df        115\n",
       "Name: dx, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_df['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future processing, we need to convert our label to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_df['cell_type_idx'] = pd.Categorical(skin_df['dx']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    6705\n",
       "4    1113\n",
       "2    1099\n",
       "1     514\n",
       "0     327\n",
       "6     142\n",
       "3     115\n",
       "Name: cell_type_idx, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_df['cell_type_idx'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the data in the form of images, and we want to convert them into matrix format that works well with PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to match up the image filenames with their corresponding image id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../SkinLesionClassifier_data'\n",
    "all_image_path = glob(os.path.join(data_dir, '*', '*.jpg'))\n",
    "imageid_path_dict = {os.path.splitext(os.path.basename(x))[0]: x for x in all_image_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "skin_df['path'] = skin_df['image_id'].map(imageid_path_dict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>cell_type_idx</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>2</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>2</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>2</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>2</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>2</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization  \\\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp   \n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp   \n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp   \n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp   \n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear   \n",
       "\n",
       "   cell_type_idx                                               path  \n",
       "0              2  ../SkinLesionClassifier_data/HAM10000_images_p...  \n",
       "1              2  ../SkinLesionClassifier_data/HAM10000_images_p...  \n",
       "2              2  ../SkinLesionClassifier_data/HAM10000_images_p...  \n",
       "3              2  ../SkinLesionClassifier_data/HAM10000_images_p...  \n",
       "4              2  ../SkinLesionClassifier_data/HAM10000_images_p...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fliter for unique lesion_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to see if `lesion_id` is unique and keep only unduplicated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5514, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will tell us how many images are associated with each lesion_id\n",
    "df_undup = skin_df.groupby('lesion_id').count()\n",
    "# now we filter out lesion_id's that have only one image associated with it\n",
    "df_undup = df_undup[df_undup['image_id'] == 1]\n",
    "df_undup.reset_index(inplace=True)\n",
    "df_undup.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5514, 9)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_id = pd.Series(df_undup['lesion_id'].unique())\n",
    "skin_df_uniq = skin_df[skin_df['lesion_id'].isin(unique_id)]\n",
    "skin_df_uniq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in image and resize it to 100 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#skin_df_uniq['image'] = skin_df_uniq['path'].map(lambda x: np.asarray(Image.open(x).resize((100,100))))\n",
    "skin_df_uniq['image'] = skin_df_uniq['path'].map(lambda x: np.asarray(Image.open(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>cell_type_idx</th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HAM_0001396</td>\n",
       "      <td>ISIC_0025276</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>2</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "      <td>[[[22, 13, 16], [22, 11, 15], [22, 11, 15], [2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>HAM_0007207</td>\n",
       "      <td>ISIC_0031326</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>65.0</td>\n",
       "      <td>male</td>\n",
       "      <td>back</td>\n",
       "      <td>2</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "      <td>[[[202, 160, 180], [198, 159, 178], [197, 160,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>HAM_0006071</td>\n",
       "      <td>ISIC_0032343</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>face</td>\n",
       "      <td>2</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>HAM_0005612</td>\n",
       "      <td>ISIC_0024981</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>2</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "      <td>[[[204, 209, 213], [205, 204, 209], [205, 203,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HAM_0005388</td>\n",
       "      <td>ISIC_0027815</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>2</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "      <td>[[[0, 0, 0], [0, 0, 0], [1, 1, 1], [6, 4, 7], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lesion_id      image_id   dx dx_type   age     sex localization  \\\n",
       "10  HAM_0001396  ISIC_0025276  bkl   histo  55.0  female        trunk   \n",
       "15  HAM_0007207  ISIC_0031326  bkl   histo  65.0    male         back   \n",
       "20  HAM_0006071  ISIC_0032343  bkl   histo  70.0  female         face   \n",
       "33  HAM_0005612  ISIC_0024981  bkl   histo  80.0    male        scalp   \n",
       "34  HAM_0005388  ISIC_0027815  bkl   histo  80.0    male        chest   \n",
       "\n",
       "    cell_type_idx                                               path  \\\n",
       "10              2  ../SkinLesionClassifier_data/HAM10000_images_p...   \n",
       "15              2  ../SkinLesionClassifier_data/HAM10000_images_p...   \n",
       "20              2  ../SkinLesionClassifier_data/HAM10000_images_p...   \n",
       "33              2  ../SkinLesionClassifier_data/HAM10000_images_p...   \n",
       "34              2  ../SkinLesionClassifier_data/HAM10000_images_p...   \n",
       "\n",
       "                                                image  \n",
       "10  [[[22, 13, 16], [22, 11, 15], [22, 11, 15], [2...  \n",
       "15  [[[202, 160, 180], [198, 159, 178], [197, 160,...  \n",
       "20  [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...  \n",
       "33  [[[204, 209, 213], [205, 204, 209], [205, 203,...  \n",
       "34  [[[0, 0, 0], [0, 0, 0], [1, 1, 1], [6, 4, 7], ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skin_df_uniq.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = skin_df_uniq.drop('cell_type_idx', axis = 1)\n",
    "target = skin_df_uniq['cell_type_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o, x_test_o, Y_train, Y_test = train_test_split(features, target, test_size=0.20,random_state=118)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_o = x_train_o.reset_index()\n",
    "x_test_o = x_test_o.reset_index()\n",
    "Y_train = Y_train.reset_index()\n",
    "Y_test = Y_test.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce bias among the pictures, we standardlize the images base on their theoretical mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_img_mean_std(df):\n",
    "    img_RGB = df['image'].values\n",
    "    RGB_vals = []\n",
    "    # for each image, get the mean for each RGB layer\n",
    "    for i in range(len(img_RGB)):\n",
    "        R = img_RGB[i][:,:,0]\n",
    "        G = img_RGB[i][:,:,1]\n",
    "        B = img_RGB[i][:,:,2]\n",
    "        RGB_vals.append([np.mean(R)/255, np.mean(G)/255, np.mean(B)/255])\n",
    "    # compute mean and std\n",
    "    RGB_vals = np.array(RGB_vals)\n",
    "    img_mean = np.mean(RGB_vals, axis = 0)\n",
    "    img_std = np.std(RGB_vals, axis = 0)\n",
    "    return img_mean, img_std\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean, train_std = compute_img_mean_std(x_train_o)\n",
    "test_mean, test_std = compute_img_mean_std(x_train_o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an image loader\n",
    "# this part is inspired \n",
    "# https://www.kaggle.com/xinruizhuang/skin-lesion-classification-acc-90-pytorch#Step-1.-Data-analysis-and-preprocessing\n",
    "class HAM10000(Dataset):\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = Image.open(self.X['path'][index])\n",
    "        #X = self.X\n",
    "        #y = torch.tensor(int(self.df['cell_type_idx'][index]))\n",
    "        y = torch.tensor(Y_train.values[:,1][index])\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>path</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9165</th>\n",
       "      <td>HAM_0007508</td>\n",
       "      <td>ISIC_0025763</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>chest</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "      <td>[[[124, 107, 113], [126, 109, 115], [124, 110,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8400</th>\n",
       "      <td>HAM_0004054</td>\n",
       "      <td>ISIC_0031756</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>male</td>\n",
       "      <td>hand</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "      <td>[[[167, 117, 106], [168, 120, 108], [170, 121,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>HAM_0003661</td>\n",
       "      <td>ISIC_0026910</td>\n",
       "      <td>nv</td>\n",
       "      <td>follow_up</td>\n",
       "      <td>35.0</td>\n",
       "      <td>female</td>\n",
       "      <td>trunk</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "      <td>[[[220, 137, 123], [224, 136, 126], [226, 138,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>HAM_0006994</td>\n",
       "      <td>ISIC_0026987</td>\n",
       "      <td>nv</td>\n",
       "      <td>histo</td>\n",
       "      <td>30.0</td>\n",
       "      <td>male</td>\n",
       "      <td>foot</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "      <td>[[[95, 48, 56], [97, 50, 58], [99, 50, 54], [9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>HAM_0002050</td>\n",
       "      <td>ISIC_0032215</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>../SkinLesionClassifier_data/HAM10000_images_p...</td>\n",
       "      <td>[[[245, 214, 211], [251, 216, 214], [250, 214,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        lesion_id      image_id   dx    dx_type   age     sex localization  \\\n",
       "9165  HAM_0007508  ISIC_0025763   nv      histo  50.0    male        chest   \n",
       "8400  HAM_0004054  ISIC_0031756   nv      histo  70.0    male         hand   \n",
       "3726  HAM_0003661  ISIC_0026910   nv  follow_up  35.0  female        trunk   \n",
       "8518  HAM_0006994  ISIC_0026987   nv      histo  30.0    male         foot   \n",
       "268   HAM_0002050  ISIC_0032215  bkl      histo  40.0    male        scalp   \n",
       "\n",
       "                                                   path  \\\n",
       "9165  ../SkinLesionClassifier_data/HAM10000_images_p...   \n",
       "8400  ../SkinLesionClassifier_data/HAM10000_images_p...   \n",
       "3726  ../SkinLesionClassifier_data/HAM10000_images_p...   \n",
       "8518  ../SkinLesionClassifier_data/HAM10000_images_p...   \n",
       "268   ../SkinLesionClassifier_data/HAM10000_images_p...   \n",
       "\n",
       "                                                  image  \n",
       "9165  [[[124, 107, 113], [126, 109, 115], [124, 110,...  \n",
       "8400  [[[167, 117, 106], [168, 120, 108], [170, 121,...  \n",
       "3726  [[[220, 137, 123], [224, 136, 126], [226, 138,...  \n",
       "8518  [[[95, 48, 56], [97, 50, 58], [99, 50, 54], [9...  \n",
       "268   [[[245, 214, 211], [251, 216, 214], [250, 214,...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_o.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 100\n",
    "train_transform = transforms.Compose([transforms.Resize((input_size,input_size)),transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomVerticalFlip(),transforms.RandomRotation(20),\n",
    "                                      transforms.ColorJitter(brightness=0.1, contrast=0.1, hue=0.1),\n",
    "                                        transforms.ToTensor(),\n",
    "                                     transforms.Normalize(train_mean, train_std)])\n",
    "# define the transformation of the val images.\n",
    "test_transform = transforms.Compose([transforms.Resize((input_size,input_size)), transforms.ToTensor(),\n",
    "                                    transforms.Normalize(test_mean, test_std)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = HAM10000(x_train_o,Y_train, transform=train_transform)\n",
    "trainloader = DataLoader(training_set, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "testing_set = HAM10000(x_test_o, Y_test,transform=test_transform)\n",
    "testloader = DataLoader(testing_set, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 100, 100])\n",
      "tensor([5, 0, 5, 4, 5, 5, 5, 5, 5, 5, 5, 4, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 0, 5,\n",
      "        5, 5, 0, 5, 5, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "## try if trainloader is working\n",
    "for i, data in enumerate(trainloader, 0):\n",
    "    # Get the inputs.\n",
    "    inputs, labels = data\n",
    "    if i == 1:\n",
    "        print(inputs.shape)\n",
    "        print(labels)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# If there are GPUs, choose the first one for computing. Otherwise use CPU.\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)  \n",
    "# If 'cuda:0' is printed, it means GPU is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's try a two-layer CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (fc2): Linear(in_features=32, out_features=12500, bias=True)\n",
       "  (fc3): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ###### Fill the blank here ######\n",
    "        # conv layer\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3, stride = 1, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3, stride = 1, padding = 1)\n",
    "        \n",
    "        # linear layer\n",
    "        #self.fc1 = nn.Linear(20 * 8 * 8, 1280) \n",
    "        self.fc2 = nn.Linear(32, 12500)\n",
    "        self.fc3 = nn.Linear(100, 10)\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        ###### Fill the blank here ######\n",
    "        # two rounds of avg pooling\n",
    "        # avg pooling over a (2, 2) window\n",
    "        x = F.avg_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.avg_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        \n",
    "        \n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        #x = self.fc1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    " \n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x): # flatten matrix\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()     # Create the network instance.\n",
    "net.to(device)  # Move the network parameters to the specified device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use cross-entropy as loss function.\n",
    "loss_func = nn.CrossEntropyLoss()  \n",
    "# We use stochastic gradient descent (SGD) as optimizer.\n",
    "opt = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [32 x 12500], m2: [32 x 12500] at /opt/conda/conda-bld/pytorch_1573049310284/work/aten/src/THC/generic/THCTensorMathBlas.cu:290",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-3f1a2144968f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Forward step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-85-45ed5d97beff>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_flat_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m#x = self.fc1(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 12500], m2: [32 x 12500] at /opt/conda/conda-bld/pytorch_1573049310284/work/aten/src/THC/generic/THCTensorMathBlas.cu:290"
     ]
    }
   ],
   "source": [
    "avg_losses = []   # Avg. losses.\n",
    "epochs = 10       # Total epochs.\n",
    "print_freq = 100  # Print frequency.\n",
    "\n",
    "for epoch in range(epochs):  # Loop over the dataset multiple times.\n",
    "    running_loss = 0.0       # Initialize running loss.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # Get the inputs.\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # Move the inputs to the specified device.\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients.\n",
    "        opt.zero_grad()\n",
    "\n",
    "        # Forward step.\n",
    "        outputs = net(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        \n",
    "        # Backward step.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Optimization step (update the parameters).\n",
    "        opt.step()\n",
    "\n",
    "        # Print statistics.\n",
    "        running_loss += loss.item()\n",
    "        if i % print_freq == print_freq - 1: # Print every several mini-batches.\n",
    "            avg_loss = running_loss / print_freq\n",
    "            print('[epoch: {}, i: {:5d}] avg mini-batch loss: {:.3f}'.format(\n",
    "                epoch, i, avg_loss))\n",
    "            avg_losses.append(avg_loss)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_losses)\n",
    "plt.xlabel('mini-batch index / {}'.format(print_freq))\n",
    "plt.ylabel('avg. mini-batch loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check several images.\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "outputs = net(images.to(device))\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test accuracy.\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test accuracy for each class.\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
